{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ultimate-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import os\n",
    "# import tweepy as tw #for accessing Twitter API\n",
    "\n",
    "\n",
    "#For Preprocessing\n",
    "import re    # RegEx for removing non-letter characters\n",
    "# import nltk  #natural language processing\n",
    "# nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "# For Building the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import tensorflow as tf\n",
    "# import seaborn as sns\n",
    "\n",
    "# #For data visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "# %matplotlib inline\n",
    "\n",
    "# pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brown-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Tweet dataset\n",
    "df = pd.read_csv('Twitter_Data.csv')\n",
    "# Output first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ethical-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_text    4\n",
      "category      7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "\n",
    "df.dropna(axis = 0, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "right-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...  Negative\n",
       "1  talk all the nonsense and continue all the dra...   Neutral\n",
       "2  what did just say vote for modi  welcome bjp t...  Positive\n",
       "3  asking his supporters prefix chowkidar their n...  Positive\n",
       "4  answer who among these the most powerful world...  Positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map tweet categories\n",
    "df['category'] = df['category'].map({-1.0:'Negative', 0.0:'Neutral', 1.0:'Positive'})\n",
    "# Output first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "original-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original tweet -> when modi promised “minimum government maximum governance” expected him begin the difficult job reforming the state why does take years get justice state should and not business and should exit psus and temples\n",
      "\n",
      "Processed tweet -> ['modi', 'promis', 'minimum', 'govern', 'maximum', 'govern', 'expect', 'begin', 'difficult', 'job', 'reform', 'state', 'take', 'year', 'get', 'justic', 'state', 'busi', 'exit', 'psu', 'templ']\n"
     ]
    }
   ],
   "source": [
    "def tweet_to_words(tweet):\n",
    "    ''' Convert tweet text into a sequence of words '''\n",
    "    \n",
    "    # convert to lowercase\n",
    "    text = tweet.lower()\n",
    "    # remove non letters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    # tokenize\n",
    "    words = text.split()\n",
    "    # remove stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    # apply stemming\n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    # return list\n",
    "    return words\n",
    "\n",
    "print(\"\\nOriginal tweet ->\", df['clean_text'][0])\n",
    "print(\"\\nProcessed tweet ->\", tweet_to_words(df['clean_text'][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "objective-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data processing to each tweet\n",
    "X = list(map(tweet_to_words, df['clean_text']))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(df['category'])\n",
    "\n",
    "# Apply data processing to each tweet\n",
    "X = list(map(tweet_to_words, df['clean_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stunning-replacement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets in the total set : 162969\n",
      "Number of tweets in the training set : 130375\n",
      "Number of tweets in the testing set : 32594\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "print('Number of tweets in the total set : {}'.format(len(X)))\n",
    "print('Number of tweets in the training set : {}'.format(len(X_train)))\n",
    "print('Number of tweets in the testing set : {}'.format(len(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "saved-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vocabulary_size = 5000\n",
    "\n",
    "# Tweets have already been preprocessed hence dummy function will be passed in \n",
    "# to preprocessor & tokenizer step\n",
    "count_vector = CountVectorizer(max_features=vocabulary_size,\n",
    "#                               ngram_range=(1,2),    # unigram and bigram\n",
    "                                preprocessor=lambda x: x,\n",
    "                               tokenizer=lambda x: x) \n",
    "#tfidf_vector = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "\n",
    "# Fit the training data\n",
    "X_train = count_vector.fit_transform(X_train).toarray()\n",
    "\n",
    "# Transform testing data\n",
    "X_test = count_vector.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "circular-microwave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NAIVE BAYES MODEL\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB() #Load Multinomial Naieve Bayeas\n",
    "#Training#\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "instrumental-locator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7438485610848622"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prediction ##\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "#ACCURACY MEASING\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "#Accuracy#\n",
    "Accuracy = accuracy_score(y_test, predicted)\n",
    "Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loved-weapon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162969, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
